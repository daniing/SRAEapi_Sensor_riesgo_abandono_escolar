{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de aprendizaje automático utilizando Fusión a nivel de Clasificador (Late Fusion)\n",
    "\n",
    "Teniendo en cuenta las heterogeneidad de las características (demográficas y académicas), se entrenaron cuatro clasificadores expertos en un tipo de característica (2 expertos en métricas) y al final se entrenó un clasificador teniendo en cuenta las probabilidades obtenidas en los clasficidadores iniciales.\n",
    "\n",
    "- Algoritmo de Random Forest para características demográficas y métricas demográficas\n",
    "- Algoritmo de Gradient Boosting para características académicas y métricas académicas\n",
    "- Algoritmo de red neuronal configuración Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import math\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from matplotlib import cm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import joblib\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report,precision_recall_curve,precision_recall_curve,precision_score,recall_score,accuracy_score,f1_score,confusion_matrix, roc_curve, auc\n",
    "import itertools\n",
    "from scipy import interp\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ini = pd.read_csv('/Users/Downloads/Dataset/Final_Dataset/Datasets/Data_1449_416_edad.csv')\n",
    "#data_comunas = pd.read_csv('/Users/Downloads/Dataset/Final_Dataset/Datasets/Data_2254_416_Comunas_edad.csv')\n",
    "\n",
    "data_ini_ = data_ini.copy()\n",
    "\n",
    "data_ini_['course_n'] = data_ini.course.replace({'SEXTO':6,'SEPTIMO':7,'OCTAVO':8,'NOVENO':9,\n",
    "                                                                 'DECIMO':10,'ONCE':11})\n",
    "\n",
    "data_demog = data_ini_[['age_frac','brother_school','gender_n','score_sisben','distance','course_n','year',\n",
    "                        'grade_n','Class']]\n",
    "\n",
    "data_acad = data_ini[['math','natural_sciences','english','spanish','peace_chair','social_sciences',\n",
    "                      'religion','arts','sports','technology','entrepreneurship','ethic', 'Class']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cox_hec</th>\n",
       "      <th>m1_d</th>\n",
       "      <th>m2_d</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.70278</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.503162e+01</td>\n",
       "      <td>0.85833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.772553e-01</td>\n",
       "      <td>1.06944</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.503162e+01</td>\n",
       "      <td>0.34444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.503162e+01</td>\n",
       "      <td>0.88333</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>6.772553e-01</td>\n",
       "      <td>0.86667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>-5.503162e+01</td>\n",
       "      <td>0.83611</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>4.22222</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>-5.503162e+01</td>\n",
       "      <td>1.88333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>-5.503162e+01</td>\n",
       "      <td>1.42222</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1865 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           cox_hec     m1_d  m2_d  Class\n",
       "0     1.000000e-10  0.70278     0      0\n",
       "1    -5.503162e+01  0.85833     0      0\n",
       "2     6.772553e-01  1.06944     0      0\n",
       "3    -5.503162e+01  0.34444     0      0\n",
       "4    -5.503162e+01  0.88333     2      0\n",
       "...            ...      ...   ...    ...\n",
       "1860  6.772553e-01  0.86667     0      1\n",
       "1861 -5.503162e+01  0.83611     0      1\n",
       "1862  1.000000e-10  4.22222     0      1\n",
       "1863 -5.503162e+01  1.88333     0      1\n",
       "1864 -5.503162e+01  1.42222     0      1\n",
       "\n",
       "[1865 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_metric_d = data_demog.copy()\n",
    "\n",
    "#data_metric_d['m1_d'] = np.where((data_metric_d['score_sisben']>=0) & (data_metric_d['score_sisben']<=11),\n",
    "#                                            1,np.where((data_metric_d['score_sisben']>11) & (data_metric_d['score_sisben']<=22),\n",
    "#                                            2,np.where((data_metric_d['score_sisben']>22) & (data_metric_d['score_sisben']<=43),\n",
    "#                                            3,np.where((data_metric_d['score_sisben']>43) & (data_metric_d['score_sisben']<=65),\n",
    "#                                            4,np.where((data_metric_d['score_sisben']>65) & (data_metric_d['score_sisben']<=79),\n",
    "#5,6)))))\n",
    "\n",
    "#bins = [0,0.5,5]\n",
    "#labels=[0,1]\n",
    "#data_metric_d['m1_d'] = pd.cut(data_metric_d['brother_school'], bins=bins, labels=labels, include_lowest=True)\n",
    "#data_final_demo_m['Métrica_d2*'] = logodds\n",
    "df = np.array(data_metric_d['brother_school']+0.0000000001)\n",
    "\n",
    "fitted_data, fitted_lambda = stats.boxcox(df)\n",
    "\n",
    "pd_hc = pd.DataFrame(fitted_data, columns=['cox_hec'])\n",
    "\n",
    "data_metric_d = pd.concat([data_metric_d, pd_hc], axis=1)\n",
    "\n",
    "data_metric_d['m1_d'] = data_metric_d['age_frac'] - (data_metric_d['course_n'] + 5)\n",
    "\n",
    "#data_final_demo_m['Métrica_d4*'] = logodds\n",
    "#data_metric_d['m2_d'] = np.where((data_metric_d['course_n']==data_metric_d['grade_n']),0,\n",
    "#                                  np.where((((2019-data_metric_d['year'])+data_metric_d['course_n'])-data_metric_d['grade_n'])<0,\n",
    "#                                            0,((2019-data_metric_d['year'])+data_metric_d['course_n'])-data_metric_d['grade_n']))\n",
    "\n",
    "data_metric_d['m2_d'] = (2019-data_metric_d['year']+data_metric_d['course_n'])-data_metric_d['grade_n']\n",
    "\n",
    "data_metric_d_ = data_metric_d[['cox_hec','m1_d','m2_d','Class']]\n",
    "\n",
    "data_metric_d_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_metric_a = data_acad.copy()\n",
    "\n",
    "data_metric_a['mCM'] = (data_metric_a['natural_sciences']+data_metric_a['math'])/2\n",
    "data_metric_a['mSC'] = (data_metric_a['social_sciences']+data_metric_a['peace_chair'])/2 \n",
    "data_metric_a['mCh'] = (data_metric_a['spanish']+data_metric_a['english'])/2\n",
    "data_metric_a['mEr'] = (data_metric_a['ethic']+data_metric_a['religion'])/2\n",
    "data_metric_a['mAt'] = (data_metric_a['arts']+data_metric_a['technology'])/2\n",
    "\n",
    "data_metric_a['mah']=(data_metric_a['natural_sciences']+data_metric_a['math']+data_metric_a['social_sciences']+data_metric_a['spanish']+data_metric_a['english'])/5\n",
    "data_metric_a['mbh']=(data_metric_a['technology']+data_metric_a['religion']+data_metric_a['peace_chair']+data_metric_a['arts']+data_metric_a['ethic']+data_metric_a['entrepreneurship']+data_metric_a['sports'])/7\n",
    "\n",
    "\n",
    "data_metric_a['m1_a'] = (data_metric_a['natural_sciences']/5)*((data_metric_a['mah']+data_metric_a['mbh'])/2)\n",
    "\n",
    "data_metric_a['m2_a'] = (data_metric_a['entrepreneurship']/5)*((data_metric_a['mah']+data_metric_a['mbh'])/2)\n",
    "\n",
    "data_metric_a['m3_a'] = (data_metric_a['math']/5)*((data_metric_a['mah']+data_metric_a['mbh'])/2)\n",
    "\n",
    "data_metric_a['m4_a'] = (data_metric_a['sports']/5)*((data_metric_a['mah']+data_metric_a['mbh'])/2)\n",
    "\n",
    "\n",
    "data_metric_a_ = data_metric_a[['mCM','mSC','mCh','mEr','mAt','mah','mbh',\n",
    "                               'm1_a','m2_a','m3_a','m4_a','Class']]\n",
    "\n",
    "data_metric_a_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demog_f = pd.DataFrame(data_demog).drop('Class', axis=1)\n",
    "\n",
    "y_d = data_demog[['Class']]\n",
    "\n",
    "dtrain, dtest, dytrain, dytest = train_test_split(data_demog_f, y_d, random_state=0, test_size = 0.3)\n",
    "\n",
    "dytrain['Class'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_metric_df = pd.DataFrame(data_metric_d_).drop('Class', axis=1)\n",
    "\n",
    "y_md = data_metric_d_[['Class']]\n",
    "\n",
    "mdtrain, mdtest, mdytrain, mdytest = train_test_split(data_metric_df, y_md, random_state=0, test_size = 0.3)\n",
    "\n",
    "mdytrain['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_acad_f = pd.DataFrame(data_acad).drop('Class', axis=1)\n",
    "\n",
    "y_a = data_acad[['Class']]\n",
    "\n",
    "atrain, atest, aytrain, aytest = train_test_split(data_acad_f, y_a, random_state=0, test_size = 0.3)\n",
    "\n",
    "ydtrain['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_metric_af = pd.DataFrame(data_metric_a_).drop('Class', axis=1)\n",
    "\n",
    "y_ma = data_metric_a_[['Class']]\n",
    "\n",
    "matrain, matest, maytrain, maytest = train_test_split(data_metric_af, y_ma, random_state=0, test_size = 0.3)\n",
    "\n",
    "ydtrain['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler().fit(dtrain)\n",
    "X_train_d = sc.transform(dtrain)\n",
    "X_test_d = sc.transform(dtest)\n",
    "\n",
    "filename_model_d = 'model_api_demog.pkl'\n",
    "\n",
    "tuned_parameters = [{'max_features': ['sqrt'], 'min_samples_leaf': [0.001],\n",
    "                     'n_estimators': [700], 'max_depth':[50],\n",
    "                     'min_samples_split':[2]}]\n",
    "clf_demog = GridSearchCV(RandomForestClassifier(bootstrap = True,class_weight='balanced'), \n",
    "                                 tuned_parameters, cv=5, scoring='roc_auc')\n",
    "\n",
    "clf_demog.fit(X_train_d, dytrain)\n",
    "\n",
    "joblib.dump(clf_demog, filename_model_d)\n",
    "print(clf_demog.best_params_)\n",
    "\n",
    "y_true1, y_pred1 = dytest, clf_demog.predict(X_test_d)\n",
    "print(classification_report(y_true1, y_pred1))\n",
    "\n",
    "print(precision_score(y_true1, y_pred1))\n",
    "print(recall_score(y_true1, y_pred1))\n",
    "print(f1_score(y_true1, y_pred1))\n",
    "print(accuracy_score(y_true1, y_pred1))\n",
    "confusion_matrix(y_true1, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler().fit(mdtrain)\n",
    "X_train_md = sc.transform(mdtrain)\n",
    "X_test_md = sc.transform(mdtest)\n",
    "\n",
    "filename_model_md = 'model_api_md.pkl'\n",
    "\n",
    "tuned_parameters = [{'max_features': [3], 'min_samples_leaf': [0.1],\n",
    "                     'n_estimators': [50], 'max_depth':[10],\n",
    "                     'min_samples_split':[10]}]\n",
    "clf_md = GridSearchCV(RandomForestClassifier(bootstrap = True,class_weight='balanced'), \n",
    "                                 tuned_parameters, cv=5, scoring='roc_auc')\n",
    "\n",
    "clf_md.fit(X_train_md, mdytrain)\n",
    "\n",
    "joblib.dump(clf_md, filename_model_md)\n",
    "print(clf_md.best_params_)\n",
    "\n",
    "y_true1, y_pred1 = mdytest, clf_md.predict(X_test_md)\n",
    "print(classification_report(y_true1, y_pred1))\n",
    "\n",
    "print(precision_score(y_true1, y_pred1))\n",
    "print(recall_score(y_true1, y_pred1))\n",
    "print(f1_score(y_true1, y_pred1))\n",
    "print(accuracy_score(y_true1, y_pred1))\n",
    "confusion_matrix(y_true1, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler().fit(atrain)\n",
    "X_train_a = sc.transform(atrain)\n",
    "X_test_a = sc.transform(atest)\n",
    "\n",
    "filename_model_a = 'model_api_a.pkl'\n",
    "tuned_parameters = [{'max_features': ['sqrt'], 'min_samples_leaf': [0.01],\n",
    "                     'n_estimators': [100], 'max_depth':[4],'learning_rate':[0.01],\n",
    "                     'min_samples_split':[2]}]\n",
    "                   \n",
    "clf_acad = GridSearchCV(GradientBoostingClassifier(),tuned_parameters, cv=5, scoring='roc_auc')\n",
    "\n",
    "clf_acad.fit(X_train_a, aytrain)\n",
    "\n",
    "joblib.dump(clf_acad, filename_model_a)\n",
    "print(clf_acad.best_params_)\n",
    "\n",
    "y_true1, y_pred1 = aytest, clf_acad.predict(X_test_a)\n",
    "print(classification_report(y_true1, y_pred1))\n",
    "\n",
    "print(precision_score(y_true1, y_pred1))\n",
    "print(recall_score(y_true1, y_pred1))\n",
    "print(f1_score(y_true1, y_pred1))\n",
    "print(accuracy_score(y_true1, y_pred1))\n",
    "confusion_matrix(y_true1, y_pred1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler().fit(matrain)\n",
    "X_train_ma = sc.transform(matrain)\n",
    "X_test_ma = sc.transform(matest)\n",
    "\n",
    "filename_model_ma = 'model_api_ma.pkl'\n",
    "tuned_parameters = [{'max_features': ['sqrt'], 'min_samples_leaf': [0.003],\n",
    "                     'n_estimators': [200], 'max_depth':[4],'learning_rate':[0.008],\n",
    "                     'min_samples_split':[2]}]\n",
    "                \n",
    "clf_ma = GridSearchCV(GradientBoostingClassifier(),tuned_parameters, cv=5, scoring='roc_auc')\n",
    "\n",
    "clf_ma.fit(X_train_ma, maytrain)\n",
    "\n",
    "joblib.dump(clf_ma, filename_model_ma)\n",
    "print(clf_ma.best_params_)\n",
    "\n",
    "y_true1, y_pred1 = maytest, clf_ma.predict(X_test_ma)\n",
    "print(classification_report(y_true1, y_pred1))\n",
    "\n",
    "print(precision_score(y_true1, y_pred1))\n",
    "print(recall_score(y_true1, y_pred1))\n",
    "print(f1_score(y_true1, y_pred1))\n",
    "print(accuracy_score(y_true1, y_pred1))\n",
    "confusion_matrix(y_true1, y_pred1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalúa los dos clasificadores entrenados previamente (para caractrísticas sociales y académicas) con la función \"predict_proba\".\n",
    "# La función \"predict_proba\" devuelve una probabilidad de clasificación para cada una de las clases\n",
    "# Para la representación late fusion se concatenan los vectores de probabilidad \n",
    "# con la confianza de cada una de las clases para ambos descriptores\n",
    "\n",
    "late_train_dam = np.hstack((clf_demog.predict_proba(X_train_d),clf_acad.predict_proba(X_train_a), \n",
    "                                  clf_md.predict_proba(X_train_md),clf_ma.predict_proba(X_train_ma)))\n",
    "late_test_dam =  np.hstack((clf_demog.predict_proba(X_test_d),clf_acad.predict_proba(X_test_a),\n",
    "                                  clf_md.predict_proba(X_test_md),clf_ma.predict_proba(X_test_ma)))\n",
    "\n",
    "\n",
    "# Entrena y evalúa el clasificador final a partir de la representación late fusion\n",
    "stdSlr3 = StandardScaler().fit(late_train_dam)\n",
    "late_train_sc = stdSlr3.transform(late_train_dam)\n",
    "late_test_sc =  stdSlr3.transform(late_test_dam)\n",
    "\n",
    "filename_latefusion = 'model_latefusion.pkl'\n",
    "\n",
    "#filename_late_all = 'clf_latefusion_metrics_svm.pkl'\n",
    "\n",
    "#tuned_parameters3 = [{'kernel': ['rbf'], 'gamma': [0.00001,0.01],\n",
    "#                     'C': [1e4, 1e5,1e6]}]\n",
    "\n",
    "#clf_m = GridSearchCV(svm.SVC(probability=True), tuned_parameters3, cv=5, scoring='roc_auc')\n",
    "#tuned_parameters3 = [{'kernel': ['rbf'], 'gamma': [0.01,0.1,1,3.75,4.25],\n",
    "#                     'C': [100,200,300,500]}]\n",
    "\n",
    "#clf_m = GridSearchCV(svm.SVC(probability=True), tuned_parameters3, cv=5, scoring='roc_auc')\n",
    "#tuned_parameters = [{'max_features': ['sqrt'], 'min_samples_leaf': [0.01],\n",
    "#                     'n_estimators': [100,500], 'max_depth':[50],'learning_rate':[0.1],\n",
    "#                     'min_samples_split':[2]}]\n",
    "#clf_m = GridSearchCV(GradientBoostingClassifier(random_state=0),tuned_parameters, cv=5, scoring='roc_auc')\n",
    "\n",
    "tuned_parameters = [{'activation': ['relu'], \n",
    "                     'solver': ['adam'],\n",
    "                     'hidden_layer_sizes': [[11,9,4]],\n",
    "                     'alpha': [0.1], 'batch_size': [64]}]\n",
    "model_latefusion = GridSearchCV(MLPClassifier(random_state=0), tuned_parameters, cv=5, scoring='roc_auc')\n",
    "\n",
    "model_latefusion.fit(late_train_sc, aytrain)\n",
    "\n",
    "joblib.dump(model_latefusion, filename_latefusion)\n",
    "\n",
    "print(model_latefusion.best_params_)\n",
    "\n",
    "y_true3_m, y_pred3_m = aytest, model_latefusion.predict(late_test_sc)\n",
    "#y_true, y_pred = y_test_1, clf_LATE.predict(late_test_scaled)\n",
    "print(classification_report(y_true3_m, y_pred3_m))\n",
    "print(precision_score(y_true3_m, y_pred3_m))\n",
    "print(recall_score(y_true3_m, y_pred3_m))\n",
    "print(f1_score(y_true3_m, y_pred3_m))\n",
    "print(accuracy_score(y_true3_m, y_pred3_m))\n",
    "confusion_matrix(y_true3_m, y_pred3_m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
